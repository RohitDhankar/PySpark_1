{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x7f4125d6cf10>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main Source -- http://spark.apache.org/docs/2.1.0/api/python/pyspark.html\n",
    "# Source --- DATAQuest --- https://www.dataquest.io/blog/apache-spark/\n",
    "\n",
    "\n",
    "sc.stop()  # To stop any other Running Spark Context\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"Daily_Show_Test1\")\n",
    " \n",
    "print sc # Not required - it shall give a diff output each time we initiate a context\n",
    "\n",
    "\n",
    "# ie -- <pyspark.context.SparkContext object at 0x7f4148bd26d0>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'YEAR\\tGoogleKnowlege_Occupation\\tShow\\tGroup\\tRaw_Guest_List',\n",
       " u'1999\\tactor\\t1/11/99\\tActing\\tMichael J. Fox',\n",
       " u'1999\\tComedian\\t1/12/99\\tComedy\\tSandra Bernhard',\n",
       " u'1999\\ttelevision actress\\t1/13/99\\tActing\\tTracey Ullman',\n",
       " u'1999\\tfilm actress\\t1/14/99\\tActing\\tGillian Anderson',\n",
       " u'1999\\tactor\\t1/18/99\\tActing\\tDavid Alan Grier',\n",
       " u'1999\\tactor\\t1/19/99\\tActing\\tWilliam Baldwin',\n",
       " u'1999\\tSinger-lyricist\\t1/20/99\\tMusician\\tMichael Stipe',\n",
       " u'1999\\tmodel\\t1/21/99\\tMedia\\tCarmen Electra',\n",
       " u'1999\\tactor\\t1/25/99\\tActing\\tMatthew Lillard',\n",
       " u'1999\\tstand-up comedian\\t1/26/99\\tComedy\\tDavid Cross',\n",
       " u'1999\\tactress\\t1/27/99\\tActing\\tYasmine Bleeth',\n",
       " u'1999\\tactor\\t1/28/99\\tActing\\tD. L. Hughley',\n",
       " u'1999\\ttelevision actress\\t10/18/99\\tActing\\tRebecca Gayheart',\n",
       " u'1999\\tComedian\\t10/19/99\\tComedy\\tSteven Wright']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# PySpark initiated with FindSpark\n",
    "# SparkContext started \n",
    "# Got CSV from ...u guessed it.\n",
    "\n",
    "# Converted CSV to TSV .. using Unix shell command -- < filename.csv tr \",\" \"\\t\" > tabfile\n",
    "# Source for above cmd -- http://www.linuxquestions.org/questions/programming-9/convert-csv-to-tab-683201/\n",
    "\n",
    "# Now importing data from TSV \n",
    "# raw_d == the SPARK RDD Object --- A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
    "# Print out top 15 Rows \n",
    "\n",
    "raw_d = sc.textFile(\"DATA_Files/dsT1.tsv\")\n",
    "\n",
    "# \n",
    "# In the above line of Code - actual Loading of CSV in RDD is Not yet Done \n",
    "# Its Done LAZILY - \"as and when ABOSULUTELY required\" as below - \n",
    "#\n",
    "\n",
    "raw_d.take(15) \n",
    "\n",
    "# The RDD Objects may Look like Pythin LISTS \n",
    "# but they are NOT - we cant access elements like a LIST with [] - square bracket notation \n",
    "# data in a RDD is stored across partitions\n",
    "# thats the reason we have to use raw_d.take()\n",
    "#\n",
    "# SPARK when running Locally - as in my case \n",
    "# simulates partitions in local Memory. \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'YEAR', u'GoogleKnowlege_Occupation', u'Show', u'Group', u'Raw_Guest_List'],\n",
       " [u'1999', u'actor', u'1/11/99', u'Acting', u'Michael J. Fox'],\n",
       " [u'1999', u'Comedian', u'1/12/99', u'Comedy', u'Sandra Bernhard'],\n",
       " [u'1999', u'television actress', u'1/13/99', u'Acting', u'Tracey Ullman'],\n",
       " [u'1999', u'film actress', u'1/14/99', u'Acting', u'Gillian Anderson']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a 'map' function operate on all elements within a RDD object\n",
    "# Each Line of the DATA is operated upon with whatever LOGIC is written within - map()\n",
    "# The line.split('\\t) --- Means Split at each TAB and create a NEW LINE \n",
    "# A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
    "\n",
    "daily_show = raw_d.map(lambda line: line.split('\\t'))     ### 'map' is a SPARK-TRANSFORMATION \n",
    "daily_show.take(5)                                        ### 'take' is a SPARK-ACTION \n",
    "\n",
    "\n",
    "\n",
    "# print daily_show # Not required \n",
    "\n",
    "# PythonRDD[12] at RDD at PythonRDD.scala:48\n",
    "\n",
    "# here the daily_show is a PIPELINE RDD Object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformations are lazy operations and always return a reference to an RDD object.\\nThe transformation, however, is not actually run until an action needs to use the\\nresulting RDD from a transformation.\\n\\nAny function that returns an RDD is a transformation\\nand any function that returns a value is an action.\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Transformations are lazy operations and always return a reference to an RDD object.\n",
    "The transformation, however, is not actually run until an action needs to use the\n",
    "resulting RDD from a transformation.\n",
    "\n",
    "Any function that returns an RDD is a transformation\n",
    "and any function that returns a value is an action.\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[21] at RDD at PythonRDD.scala:48\n",
      "  \n",
      "__#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#_____#___\n",
      "  \n",
      "[(u'1999', 166), (u'2002', 159), (u'2000', 169), (u'2006', 161), (u'2004', 164), (u'2015', 100), (u'2008', 164), (u'2011', 163), (u'2013', 166), (u'2005', 162), (u'2003', 166), (u'2001', 157), (u'2007', 141), (u'YEAR', 1), (u'2014', 163), (u'2009', 163), (u'2010', 165), (u'2012', 164)]\n"
     ]
    }
   ],
   "source": [
    "# The map() - is a SPARK-TRANSFORMATION \n",
    "# The ReduceByKey() - is a SPARK-TRANSFORMATION \n",
    "\n",
    "tally = daily_show.map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y)\n",
    "#\n",
    "\n",
    "print(tally)\n",
    "#\n",
    "print(\"  \")\n",
    "print(\"__#___\"*20)\n",
    "print(\"  \")\n",
    "#\n",
    "print(tally.take(20))\n",
    "\n",
    "#\n",
    "# PythonRDD[18] at RDD at PythonRDD.scala:48\n",
    "# Doesnt actually Print the TALLY \n",
    "# We need --- Key + Value -- Where KEY is a YEAR == 1991 and VALUE is \"How Many Guests or LINES in that Year\"\n",
    "# How many lines of data have the same YEAR == 1991 value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1999', 166),\n",
       " (u'2002', 159),\n",
       " (u'2000', 169),\n",
       " (u'2006', 161),\n",
       " (u'2004', 164),\n",
       " (u'2015', 100),\n",
       " (u'2008', 164),\n",
       " (u'2011', 163),\n",
       " (u'2013', 166),\n",
       " (u'2005', 162),\n",
       " (u'2003', 166),\n",
       " (u'2001', 157),\n",
       " (u'2007', 141),\n",
       " (u'YEAR', 1),\n",
       " (u'2014', 163),\n",
       " (u'2009', 163),\n",
       " (u'2010', 165),\n",
       " (u'2012', 164)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 'tally'  - Frequency of Occurence of Year Value -HistoGram !\n",
    "## As we cant measure LENGTH of the TALLY Object which is a RDD and a LIST of TUPLES \n",
    "## We shall COUNT its total elements\n",
    "## Each TUPLE has a KEY == 1999,2002,2000 etc ...\n",
    "## Each TUPLE also has Values == 166,159,169 etc ...\n",
    "\n",
    "tally.take(tally.count())\n",
    "\n",
    "# Seen below the -- (u'YEAR', 1), is the 1 single occurence of STRING -- YEAR\n",
    "# Spark doesnt create COLUMN HEADERS , Column Lablels like Python \n",
    "# So we need to get rid of this GARBAGE value ... its of no use to us. \n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'1999', u'actor', u'1/11/99', u'Acting', u'Michael J. Fox'], [u'1999', u'Comedian', u'1/12/99', u'Comedy', u'Sandra Bernhard'], [u'1999', u'television actress', u'1/13/99', u'Acting', u'Tracey Ullman'], [u'1999', u'film actress', u'1/14/99', u'Acting', u'Gillian Anderson'], [u'1999', u'actor', u'1/18/99', u'Acting', u'David Alan Grier'], [u'1999', u'actor', u'1/19/99', u'Acting', u'William Baldwin'], [u'1999', u'Singer-lyricist', u'1/20/99', u'Musician', u'Michael Stipe'], [u'1999', u'model', u'1/21/99', u'Media', u'Carmen Electra'], [u'1999', u'actor', u'1/25/99', u'Acting', u'Matthew Lillard'], [u'1999', u'stand-up comedian', u'1/26/99', u'Comedy', u'David Cross'], [u'1999', u'actress', u'1/27/99', u'Acting', u'Yasmine Bleeth'], [u'1999', u'actor', u'1/28/99', u'Acting', u'D. L. Hughley'], [u'1999', u'television actress', u'10/18/99', u'Acting', u'Rebecca Gayheart'], [u'1999', u'Comedian', u'10/19/99', u'Comedy', u'Steven Wright'], [u'1999', u'actress', u'10/20/99', u'Acting', u'Amy Brenneman'], [u'1999', u'actress', u'10/21/99', u'Acting', u'Melissa Gilbert'], [u'1999', u'actress', u'10/25/99', u'Acting', u'Cathy Moriarty'], [u'1999', u'comedian', u'10/26/99', u'Comedy', u'Louie Anderson'], [u'1999', u'actress', u'10/27/99', u'Acting', u'Sarah Michelle Gellar'], [u'1999', u'Singer-songwriter', u'10/28/99', u'Musician', u'Melanie C']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Spark RDD's are Immutable - like Py TUPLES-- values cant be changed once created ...\n",
    "# Cant remove the line which is a Pseudo Column Header == (u'YEAR', 1),\n",
    "# Thus need to create another RDD using Filter \n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "def filter_year(line):                    # filter_year FUNCTION  - defined here\n",
    "    if line[0] == 'YEAR':                 # if line[0] == YEAR give a FALSE else a TRUE \n",
    "        return False                      # Thus besides YEAR:1 , all values TRUE\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "# Filter here gives us a     \n",
    "\n",
    "filtered_daily_show = daily_show.filter(lambda line: filter_year(line)) # lamda line: similar to FOR Loop Each Line  \n",
    "\n",
    "print(filtered_daily_show.take(20))\n",
    "\n",
    "# As seen below - the background processing is being done by SCALA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'secretary of state', 1),\n",
       " (u'former president of the maldives', 1),\n",
       " (u'professional road racing cyclist', 2),\n",
       " (u'actress', 271),\n",
       " (u'television series creator', 3),\n",
       " (u'former governor of illinois', 2),\n",
       " (u'telvision personality', 1),\n",
       " (u'economist', 17),\n",
       " (u'attorney at law', 1),\n",
       " (u'baseball player', 8),\n",
       " (u'former american senator', 4),\n",
       " (u'former governor of nebraska', 4),\n",
       " (u'freelance writer', 2),\n",
       " (u'former mayor of cincinatti', 2),\n",
       " (u'former united states national security advisor', 1),\n",
       " (u'astronaut', 2),\n",
       " (u'soccer manager', 2),\n",
       " (u'public speaker', 1),\n",
       " (u'hip-hop artist', 2),\n",
       " (u'political consultant', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 11. All together now ##\n",
    "\n",
    "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
    "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
    "                   .reduceByKey(lambda x,y: x+y) \\\n",
    ".take(20)\n",
    "\n",
    "# Clearly the Daily Show likes Actresses \n",
    "# u'actress', 271\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getConf()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
